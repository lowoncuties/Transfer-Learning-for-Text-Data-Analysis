{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FastText_IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and utility functions"
      ],
      "metadata": {
        "id": "iv7PLyjbJV5b"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43AiImZRqXjT"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import matplotlib.image as mpimg # images\n",
        "import numpy as np #numpy\n",
        "import seaborn as sns\n",
        "import tensorflow.compat.v2 as tf #use tensorflow v2 as a main \n",
        "import tensorflow.keras as keras # required for high level applications\n",
        "from sklearn.model_selection import train_test_split # split for validation sets\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import normalize # normalization of the matrix\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imembF7Xqb_z"
      },
      "source": [
        "def cleanTexts(texts):\n",
        "    cleaned = []\n",
        "    pattern = \"[^a-zA-Z0-9]\"\n",
        "    for text in texts:\n",
        "        clrd = re.sub(pattern,\" \",text).lower().strip()\n",
        "        cleaned.append(clrd)\n",
        "    return cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "8pO-6vUvJakx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iv9SP1AoyuJe",
        "outputId": "1592efb4-cccc-4333-fe73-bfe8a533525c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                               text  label\n",
              "12341       23856  Why would any legitimate actor having read the...      0\n",
              "17921        6432  And my children love it now! Granted, I can wa...      1\n",
              "1233         4408  Using Buster Keaton in the twilight of his car...      1\n",
              "13700       14169  Minimal script, minimal character development,...      0\n",
              "10062        8556  Not really a big box office draw, but I was pl...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83303ba9-8fbd-42aa-8592-9898df4aeda8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12341</th>\n",
              "      <td>23856</td>\n",
              "      <td>Why would any legitimate actor having read the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17921</th>\n",
              "      <td>6432</td>\n",
              "      <td>And my children love it now! Granted, I can wa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>4408</td>\n",
              "      <td>Using Buster Keaton in the twilight of his car...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13700</th>\n",
              "      <td>14169</td>\n",
              "      <td>Minimal script, minimal character development,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10062</th>\n",
              "      <td>8556</td>\n",
              "      <td>Not really a big box office draw, but I was pl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83303ba9-8fbd-42aa-8592-9898df4aeda8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83303ba9-8fbd-42aa-8592-9898df4aeda8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83303ba9-8fbd-42aa-8592-9898df4aeda8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "dataset = pd.read_csv('train_data_imdb.csv')\n",
        "dataset = shuffle(dataset)\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9xLnaYVy17r"
      },
      "outputs": [],
      "source": [
        "x_train = list(cleanTexts(dataset['text']))\n",
        "# print(x[:5])\n",
        "\n",
        "y_train = list(dataset['label'])\n",
        "# print(y[:5])\n",
        "\n",
        "#x_train = x_train[:10000]\n",
        "#y_train = y_train[:10000]\n",
        "\n",
        "x_train = x_train[:25000]\n",
        "y_train = y_train[:25000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsiB621yy1-a"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('test_data_imdb.csv')\n",
        "\n",
        "x_test = list(cleanTexts(test_data['text']))\n",
        "y_test = list(test_data['label'])\n",
        "\n",
        "x_test = x_test[:10000]\n",
        "y_test = y_test[:10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model and predict on test dataset"
      ],
      "metadata": {
        "id": "XHCC8u1-KJQB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHPU07Ouqna_"
      },
      "source": [
        "from tensorflow import string as tf_string\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNGRU, CuDNNLSTM\n",
        "from tensorflow.keras.layers import LSTM, GRU, Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import FastText embeddings"
      ],
      "metadata": {
        "id": "mocNNkwlKhy5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saAFGV2VxYof",
        "outputId": "f9d4a75e-c49f-4661-c94a-e67bb65c3dd7"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-17 10:54:43--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1325960915 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.en.300.vec.gz’\n",
            "\n",
            "cc.en.300.vec.gz    100%[===================>]   1.23G  17.2MB/s    in 69s     \n",
            "\n",
            "2022-04-17 10:55:53 (18.3 MB/s) - ‘cc.en.300.vec.gz’ saved [1325960915/1325960915]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23L0-NCxlQnu"
      },
      "source": [
        "import gzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7YEFk6nQB1-"
      },
      "source": [
        "!gzip -d cc.en.300.vec.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIQAQzmhQB_K",
        "outputId": "9de5e316-ea86-4515-f45f-fca8f282566e"
      },
      "source": [
        "path_to_fasttext_file = './cc.en.300.vec'\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_fasttext_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - 4 Vectorizer parameters"
      ],
      "metadata": {
        "id": "xwcaBzTKK2G2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FeYQiSWQCG9"
      },
      "source": [
        "from tensorflow import string as tf_string\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "embedding_dim = 300 # Dimension of embedded representation \n",
        "vocab_size = 30000 # Number of unique tokens in vocabulary\n",
        "sequence_length = 128 # Output dimension after vectorizing\n",
        "\n",
        "vect_layer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
        "vect_layer.adapt(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAN_NtlRQIL7"
      },
      "source": [
        "voc = vect_layer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PneEQsZQIXa",
        "outputId": "f4092dbf-f07c-4496-f104-ef23a5209ac6"
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 28300 words (1700 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INpD6UAIqsM6"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=69, stratify=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Experiment"
      ],
      "metadata": {
        "id": "EjTy6eY2LhKe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775d194f-98da-4799-8417-267870908fa0",
        "id": "1ujN4EaqLki1"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = LSTM(64, activation='relu', return_sequences=True)(emb)\n",
        "x = keras.layers.Dropout(0.6)(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dropout(0.6)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (TextV  (None, 128)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_17 (Embedding)    (None, 128, 300)          9000600   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128, 128)         186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 128, 128)          0         \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 16384)             0         \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 16385     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,203,865\n",
            "Trainable params: 203,265\n",
            "Non-trainable params: 9,000,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b296aa-346b-4449-f3ff-415a3a07a86b",
        "id": "LDZTY8dQLki3"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 14\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "12/12 [==============================] - 8s 521ms/step - loss: 0.6921 - accuracy: 0.5199 - val_loss: 0.6845 - val_accuracy: 0.5240\n",
            "Epoch 2/14\n",
            "12/12 [==============================] - 7s 575ms/step - loss: 0.6774 - accuracy: 0.5702 - val_loss: 0.6680 - val_accuracy: 0.5720\n",
            "Epoch 3/14\n",
            "12/12 [==============================] - 6s 477ms/step - loss: 0.6554 - accuracy: 0.6153 - val_loss: 0.6364 - val_accuracy: 0.6320\n",
            "Epoch 4/14\n",
            "12/12 [==============================] - 6s 480ms/step - loss: 0.6129 - accuracy: 0.6647 - val_loss: 0.5890 - val_accuracy: 0.6970\n",
            "Epoch 5/14\n",
            "12/12 [==============================] - 6s 473ms/step - loss: 198.2994 - accuracy: 0.7261 - val_loss: 0.5567 - val_accuracy: 0.7170\n",
            "Epoch 6/14\n",
            "12/12 [==============================] - 6s 486ms/step - loss: 0.5297 - accuracy: 0.7386 - val_loss: 0.5279 - val_accuracy: 0.7440\n",
            "Epoch 7/14\n",
            "12/12 [==============================] - 6s 475ms/step - loss: 87.3008 - accuracy: 0.7453 - val_loss: 0.8457 - val_accuracy: 0.5660\n",
            "Epoch 8/14\n",
            "12/12 [==============================] - 6s 468ms/step - loss: 3226.9233 - accuracy: 0.6253 - val_loss: 0.5534 - val_accuracy: 0.7340\n",
            "Epoch 9/14\n",
            "12/12 [==============================] - 6s 461ms/step - loss: 555659.0000 - accuracy: 0.7166 - val_loss: 0.5582 - val_accuracy: 0.7040\n",
            "Epoch 10/14\n",
            "12/12 [==============================] - 6s 461ms/step - loss: 0.5199 - accuracy: 0.7543 - val_loss: 0.5263 - val_accuracy: 0.7430\n",
            "Epoch 11/14\n",
            "12/12 [==============================] - 6s 472ms/step - loss: 0.5073 - accuracy: 0.7658 - val_loss: 0.5108 - val_accuracy: 0.7590\n",
            "Epoch 12/14\n",
            "12/12 [==============================] - 6s 470ms/step - loss: 0.5013 - accuracy: 0.7688 - val_loss: 0.5083 - val_accuracy: 0.7640\n",
            "Epoch 13/14\n",
            "12/12 [==============================] - 6s 537ms/step - loss: 0.4952 - accuracy: 0.7711 - val_loss: 0.5062 - val_accuracy: 0.7600\n",
            "Epoch 14/14\n",
            "12/12 [==============================] - 6s 472ms/step - loss: 0.4949 - accuracy: 0.7704 - val_loss: 0.5035 - val_accuracy: 0.7660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rpC926WLki4"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b7edbd-0190-4b28-d941-d5ef9ef32a49",
        "id": "E2mm5w-dLki4"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 78.79% \n",
            "f1-score is 0.8091424457842168% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.68      0.76      4984\n",
            "           1       0.74      0.90      0.81      5016\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.80      0.79      0.79     10000\n",
            "weighted avg       0.80      0.79      0.79     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Experiment"
      ],
      "metadata": {
        "id": "VlejxcadSwzB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26caeb36-7b75-4f79-9a21-8faa3f3e3c76",
        "id": "CGOrF-N1ToHQ"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(emb)\n",
        "x = keras.layers.Dropout(0.6)(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dropout(0.6)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (TextV  (None, 128)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_18 (Embedding)    (None, 128, 300)          9000600   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 128, 128)         186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 128, 128)          0         \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 16384)             0         \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 1)                 16385     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,203,865\n",
            "Trainable params: 203,265\n",
            "Non-trainable params: 9,000,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-D7WfnmSyV6",
        "outputId": "36f2a2c8-d67e-4584-89d4-593024afa53f"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 14\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "12/12 [==============================] - 6s 484ms/step - loss: 0.5559 - accuracy: 0.7184 - val_loss: 0.5542 - val_accuracy: 0.7210\n",
            "Epoch 2/14\n",
            "12/12 [==============================] - 6s 471ms/step - loss: 0.5521 - accuracy: 0.7201 - val_loss: 0.5531 - val_accuracy: 0.7210\n",
            "Epoch 3/14\n",
            "12/12 [==============================] - 6s 467ms/step - loss: 0.5516 - accuracy: 0.7258 - val_loss: 0.5522 - val_accuracy: 0.7230\n",
            "Epoch 4/14\n",
            "12/12 [==============================] - 6s 473ms/step - loss: 0.5485 - accuracy: 0.7311 - val_loss: 0.5514 - val_accuracy: 0.7240\n",
            "Epoch 5/14\n",
            "12/12 [==============================] - 6s 482ms/step - loss: 0.5502 - accuracy: 0.7249 - val_loss: 0.5503 - val_accuracy: 0.7220\n",
            "Epoch 6/14\n",
            "12/12 [==============================] - 6s 460ms/step - loss: 0.5486 - accuracy: 0.7248 - val_loss: 0.5495 - val_accuracy: 0.7230\n",
            "Epoch 7/14\n",
            "12/12 [==============================] - 6s 475ms/step - loss: 0.5482 - accuracy: 0.7260 - val_loss: 0.5489 - val_accuracy: 0.7230\n",
            "Epoch 8/14\n",
            "12/12 [==============================] - 6s 475ms/step - loss: 0.5481 - accuracy: 0.7263 - val_loss: 0.5479 - val_accuracy: 0.7190\n",
            "Epoch 9/14\n",
            "12/12 [==============================] - 6s 464ms/step - loss: 0.5445 - accuracy: 0.7280 - val_loss: 0.5475 - val_accuracy: 0.7250\n",
            "Epoch 10/14\n",
            "12/12 [==============================] - 6s 469ms/step - loss: 0.5445 - accuracy: 0.7279 - val_loss: 0.5473 - val_accuracy: 0.7270\n",
            "Epoch 11/14\n",
            "12/12 [==============================] - 6s 477ms/step - loss: 0.5470 - accuracy: 0.7282 - val_loss: 0.5462 - val_accuracy: 0.7280\n",
            "Epoch 12/14\n",
            "12/12 [==============================] - 6s 478ms/step - loss: 0.5408 - accuracy: 0.7320 - val_loss: 0.5457 - val_accuracy: 0.7270\n",
            "Epoch 13/14\n",
            "12/12 [==============================] - 6s 472ms/step - loss: 0.5438 - accuracy: 0.7331 - val_loss: 0.5452 - val_accuracy: 0.7270\n",
            "Epoch 14/14\n",
            "12/12 [==============================] - 6s 481ms/step - loss: 0.5433 - accuracy: 0.7274 - val_loss: 0.5445 - val_accuracy: 0.7300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f301cdc2-7463-41f1-cee1-1605ccd65766",
        "id": "Y1YydQsdSyV7"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 12s 40ms/step - loss: 0.5521 - accuracy: 0.7289\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5521315336227417, 0.7289000153541565]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34af461-8bef-4e0b-f408-5cae6a87454f",
        "id": "K7cgFyu0SyV7"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 72.89% \n",
            "f1-score is 0.726078609679701% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.74      0.73      4984\n",
            "           1       0.74      0.72      0.73      5016\n",
            "\n",
            "    accuracy                           0.73     10000\n",
            "   macro avg       0.73      0.73      0.73     10000\n",
            "weighted avg       0.73      0.73      0.73     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Experiment"
      ],
      "metadata": {
        "id": "kvr7L3PWVQwp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadd8005-1031-4234-f7b6-3cda106d474d",
        "id": "V3XwvtatVQxG"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = LSTM(128, activation='relu', return_sequences=True)(emb)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = GRU(128, activation='relu', return_sequences=True)(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(128, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_21 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_3 (TextV  (None, 128)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_20 (Embedding)    (None, 128, 300)          9000600   \n",
            "                                                                 \n",
            " lstm_21 (LSTM)              (None, 128, 128)          219648    \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 128, 128)          0         \n",
            "                                                                 \n",
            " gru_10 (GRU)                (None, 128, 128)          99072     \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 128)               2097280   \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,426,969\n",
            "Trainable params: 2,426,369\n",
            "Non-trainable params: 9,000,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313e64eb-80fd-4441-f142-491ad0ff0efa",
        "id": "bNTGoZN_VQxH"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 8\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "30/30 [==============================] - 19s 551ms/step - loss: 0.6766 - accuracy: 0.5671 - val_loss: 0.6312 - val_accuracy: 0.6680\n",
            "Epoch 2/8\n",
            "30/30 [==============================] - 17s 580ms/step - loss: 0.5585 - accuracy: 0.7216 - val_loss: 0.4711 - val_accuracy: 0.7832\n",
            "Epoch 3/8\n",
            "30/30 [==============================] - 27s 881ms/step - loss: 0.4630 - accuracy: 0.7867 - val_loss: 0.4223 - val_accuracy: 0.8100\n",
            "Epoch 4/8\n",
            "30/30 [==============================] - 16s 528ms/step - loss: 0.4223 - accuracy: 0.8115 - val_loss: 0.3923 - val_accuracy: 0.8288\n",
            "Epoch 5/8\n",
            "30/30 [==============================] - 16s 530ms/step - loss: 0.4025 - accuracy: 0.8232 - val_loss: 0.3857 - val_accuracy: 0.8264\n",
            "Epoch 6/8\n",
            "30/30 [==============================] - 16s 521ms/step - loss: 0.3784 - accuracy: 0.8349 - val_loss: 0.3705 - val_accuracy: 0.8408\n",
            "Epoch 7/8\n",
            "30/30 [==============================] - 16s 531ms/step - loss: 0.3714 - accuracy: 0.8376 - val_loss: 0.3645 - val_accuracy: 0.8540\n",
            "Epoch 8/8\n",
            "30/30 [==============================] - 17s 556ms/step - loss: 0.3458 - accuracy: 0.8535 - val_loss: 0.3463 - val_accuracy: 0.8516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebb5ec4-c1c0-4d71-b8f0-8383017250ba",
        "id": "4nzv-ZbTVQxI"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 16s 51ms/step - loss: 0.3583 - accuracy: 0.8447\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35831525921821594, 0.8446999788284302]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc004b74-03dd-41dd-be42-cbf9efbe8d2f",
        "id": "hJ5sYov2VQxJ"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 84.47% \n",
            "f1-score is 0.8460089241447694% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84      4984\n",
            "           1       0.84      0.85      0.85      5016\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Experiment"
      ],
      "metadata": {
        "id": "h4V65JEZVQxJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ee9e01-e843-487a-f94a-8c126930a2b3",
        "id": "kyS6e2RnVQxK"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = Bidirectional(LSTM(128, activation='relu', return_sequences=True))(emb)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = Bidirectional(GRU(128, activation='relu', return_sequences=True))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(128, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_27 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_3 (TextV  (None, 128)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_26 (Embedding)    (None, 128, 300)          9000600   \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirecti  (None, 128, 256)         439296    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 128, 256)          0         \n",
            "                                                                 \n",
            " bidirectional_14 (Bidirecti  (None, 128, 256)         296448    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_25 (Flatten)        (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_68 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,941,145\n",
            "Trainable params: 4,940,545\n",
            "Non-trainable params: 9,000,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82871b02-acad-4608-ad6b-822135c2cf77",
        "id": "hLYhWJfXVQxL"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 6\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "30/30 [==============================] - 77s 1s/step - loss: 0.6886 - accuracy: 0.5378 - val_loss: 0.6594 - val_accuracy: 0.6060\n",
            "Epoch 2/6\n",
            "30/30 [==============================] - 30s 1s/step - loss: 0.5741 - accuracy: 0.7091 - val_loss: 0.5363 - val_accuracy: 0.7432\n",
            "Epoch 3/6\n",
            "30/30 [==============================] - 31s 1s/step - loss: 0.4661 - accuracy: 0.7880 - val_loss: 0.4549 - val_accuracy: 0.7856\n",
            "Epoch 4/6\n",
            "30/30 [==============================] - 30s 999ms/step - loss: 0.4222 - accuracy: 0.8132 - val_loss: 0.4087 - val_accuracy: 0.8112\n",
            "Epoch 5/6\n",
            "30/30 [==============================] - 30s 1s/step - loss: 0.3924 - accuracy: 0.8309 - val_loss: 0.3708 - val_accuracy: 0.8372\n",
            "Epoch 6/6\n",
            "30/30 [==============================] - 30s 997ms/step - loss: 0.3651 - accuracy: 0.8439 - val_loss: 0.4000 - val_accuracy: 0.8220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8102cf-8b2e-4f01-de17-f23244b1b712",
        "id": "X84oXZMCVQxL"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 26s 82ms/step - loss: 0.3653 - accuracy: 0.8405\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3652898073196411, 0.840499997138977]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASBphMfiVQxM"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - 6 Vectorizer parameters"
      ],
      "metadata": {
        "id": "mOZz6DbnZGbi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AimXOKjoZEm3"
      },
      "source": [
        "from tensorflow import string as tf_string\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "embedding_dim = 300 # Dimension of embedded representation\n",
        "vocab_size = 100000 # Number of unique tokens in vocabulary\n",
        "sequence_length = 250 # Output dimension after vectorizing \n",
        "\n",
        "vect_layer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
        "vect_layer.adapt(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlADj_6GZEm4"
      },
      "source": [
        "voc = vect_layer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e17e320-6729-4800-b95f-20d1689d56ee",
        "id": "dU8hi9RZZEm5"
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 59576 words (14907 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5TfsE_6ZEm6"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=69, stratify=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Experiment"
      ],
      "metadata": {
        "id": "6sm2R_T9Leys"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51DQtGKkQOJw",
        "outputId": "1a167471-02d9-4e0a-b02d-ee4fd60bc38c"
      },
      "source": [
        "#4\n",
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(emb)\n",
        "#x = Bidirectional(GRU(64, activation='relu', return_sequences=False))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(128, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_9 (TextV  (None, 300)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_18 (Embedding)    (None, 300, 300)          22345500  \n",
            "                                                                 \n",
            " bidirectional_27 (Bidirecti  (None, 300, 128)         186880    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 38400)             0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 128)               4915328   \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,458,077\n",
            "Trainable params: 5,112,577\n",
            "Non-trainable params: 22,345,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8uLdVwmQON5"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 6\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYiP3GM3QSyU"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cef6sDNsQS1z"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpQds4tpQS-y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Experiment"
      ],
      "metadata": {
        "id": "gmsvKEDhbAGR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47a0aee-ec5a-486a-b5b8-f1a27c22fe97",
        "id": "LKWoKa28a-9N"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = Bidirectional(LSTM(128, activation='relu', return_sequences=True))(emb)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = Bidirectional(LSTM(128))(x)\n",
        "x = keras.layers.Dense(128, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_29 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_4 (TextV  (None, 250)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_28 (Embedding)    (None, 250, 300)          22345500  \n",
            "                                                                 \n",
            " bidirectional_17 (Bidirecti  (None, 250, 256)         439296    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 250, 256)          0         \n",
            "                                                                 \n",
            " bidirectional_18 (Bidirecti  (None, 256)              394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,222,301\n",
            "Trainable params: 876,801\n",
            "Non-trainable params: 22,345,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-lIqSO_a-9O",
        "outputId": "4cb961a6-120d-4724-cf4a-9df58204a615"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 6\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "30/30 [==============================] - 40s 1s/step - loss: 0.6837 - accuracy: 0.5531 - val_loss: 0.6334 - val_accuracy: 0.6480\n",
            "Epoch 2/6\n",
            "30/30 [==============================] - 32s 1s/step - loss: 0.5955 - accuracy: 0.6977 - val_loss: 0.4962 - val_accuracy: 0.7676\n",
            "Epoch 3/6\n",
            "30/30 [==============================] - 33s 1s/step - loss: 0.5250 - accuracy: 0.7603 - val_loss: 0.4817 - val_accuracy: 0.7848\n",
            "Epoch 4/6\n",
            "30/30 [==============================] - 32s 1s/step - loss: 0.4447 - accuracy: 0.8082 - val_loss: 0.4048 - val_accuracy: 0.8268\n",
            "Epoch 5/6\n",
            "30/30 [==============================] - 33s 1s/step - loss: 0.3903 - accuracy: 0.8362 - val_loss: 0.3753 - val_accuracy: 0.8384\n",
            "Epoch 6/6\n",
            "30/30 [==============================] - 33s 1s/step - loss: 0.3625 - accuracy: 0.8495 - val_loss: 0.3552 - val_accuracy: 0.8488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6VabYBJa-9P",
        "outputId": "0876af9c-6e86-46c0-b814-207552b4f574"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 28s 89ms/step - loss: 0.3599 - accuracy: 0.8489\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3598681688308716, 0.8489000201225281]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAJbU-tja-9P",
        "outputId": "e84d06ed-ecd1-40ae-d2c4-671d43f97fd7"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 84.89% \n",
            "f1-score is 0.8502626102467544% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85      4984\n",
            "           1       0.85      0.86      0.85      5016\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model"
      ],
      "metadata": {
        "id": "7gbgrDU9Y9BR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-urKYDgq-un",
        "outputId": "26c8d91d-e4e6-4e6a-af9f-3691d8b43c23"
      },
      "source": [
        "model.save('IMDB_FT_fourth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: FR_LSTM_sixth/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f36c1b79210> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f36c1f49d90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wgbyYDl-JSi",
        "outputId": "046ec7a0-829e-459f-b83e-e78e36ffc9c8"
      },
      "source": [
        "!zip -r /content/IMDB_FT_first.zip /content/IMDB_FT_first/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/FR_LSTM_sixth/ (stored 0%)\n",
            "  adding: content/FR_LSTM_sixth/variables/ (stored 0%)\n",
            "  adding: content/FR_LSTM_sixth/variables/variables.index (deflated 67%)\n",
            "  adding: content/FR_LSTM_sixth/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/FR_LSTM_sixth/assets/ (stored 0%)\n",
            "  adding: content/FR_LSTM_sixth/keras_metadata.pb (deflated 90%)\n",
            "  adding: content/FR_LSTM_sixth/saved_model.pb (deflated 78%)\n"
          ]
        }
      ]
    }
  ]
}