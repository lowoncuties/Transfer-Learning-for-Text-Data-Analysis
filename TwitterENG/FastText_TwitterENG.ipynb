{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FastText_TwitterENG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and utility functions"
      ],
      "metadata": {
        "id": "STfDoRm8jat2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N65_y8DNcMir"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import matplotlib.image as mpimg # images\n",
        "import numpy as np #numpy\n",
        "import seaborn as sns\n",
        "import tensorflow.compat.v2 as tf #use tensorflow v2 as a main \n",
        "import tensorflow.keras as keras # required for high level applications\n",
        "from sklearn.model_selection import train_test_split # split for validation sets\n",
        "from sklearn.metrics import accuracy_score, f1_score,classification_report\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftTsxgxocRPL"
      },
      "source": [
        "def cleanTexts(texts):\n",
        "    cleaned = []\n",
        "    pattern = \"[^a-zA-Z0-9]\"\n",
        "    for text in texts:\n",
        "        clrd = re.sub(pattern,\" \",text).lower().strip()\n",
        "        cleaned.append(clrd)\n",
        "    return cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "q1IIABmJh4LC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iv9SP1AoyuJe",
        "outputId": "e9013dde-deeb-4a3e-f46c-186d01ddebac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  label\n",
              "79206   @justEdith Ah, Shuckle berries, eye think you'...      1\n",
              "312574  nothing beats being vomited on at 2am by your ...      0\n",
              "630603                             Washing windows today       1\n",
              "498472  First day off this week,and it's already over!...      0\n",
              "495358  @RetroRewind yes, Games first. Then can we fol...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f65082e0-e357-458c-a8bf-dac60d89349e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>79206</th>\n",
              "      <td>@justEdith Ah, Shuckle berries, eye think you'...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312574</th>\n",
              "      <td>nothing beats being vomited on at 2am by your ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630603</th>\n",
              "      <td>Washing windows today</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498472</th>\n",
              "      <td>First day off this week,and it's already over!...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495358</th>\n",
              "      <td>@RetroRewind yes, Games first. Then can we fol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f65082e0-e357-458c-a8bf-dac60d89349e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f65082e0-e357-458c-a8bf-dac60d89349e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f65082e0-e357-458c-a8bf-dac60d89349e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "dataset = pd.read_csv('train_data_tweetsENG.csv')\n",
        "dataset = shuffle(dataset)\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9xLnaYVy17r"
      },
      "outputs": [],
      "source": [
        "x_train = list(cleanTexts(dataset['text']))\n",
        "# print(x[:5])\n",
        "\n",
        "y_train = list(dataset['label'])\n",
        "# print(y[:5])\n",
        "\n",
        "#x_train = x_train[:20000]\n",
        "#y_train = y_train[:20000]\n",
        "\n",
        "#x_train = x_train[:500000]\n",
        "#y_train = y_train[:500000]\n",
        "\n",
        "x_train = x_train[:900000]\n",
        "y_train = y_train[:900000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsiB621yy1-a"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('test_data_tweetsENG.csv')\n",
        "\n",
        "x_test = list(cleanTexts(test_data['text']))\n",
        "y_test = list(test_data['label'])\n",
        "\n",
        "x_test = x_test[:10000]\n",
        "y_test = y_test[:10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model and predict on test dataset"
      ],
      "metadata": {
        "id": "XHCC8u1-KJQB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHPU07Ouqna_"
      },
      "source": [
        "from tensorflow import string as tf_string\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNGRU, CuDNNLSTM\n",
        "from tensorflow.keras.layers import LSTM, GRU, Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import FastText embeddings"
      ],
      "metadata": {
        "id": "mocNNkwlKhy5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saAFGV2VxYof",
        "outputId": "8a9a788a-2e79-488b-8b05-86002bbd213b"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-17 14:24:43--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1325960915 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.en.300.vec.gz’\n",
            "\n",
            "cc.en.300.vec.gz    100%[===================>]   1.23G  56.1MB/s    in 24s     \n",
            "\n",
            "2022-04-17 14:25:07 (52.5 MB/s) - ‘cc.en.300.vec.gz’ saved [1325960915/1325960915]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23L0-NCxlQnu"
      },
      "source": [
        "import gzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7YEFk6nQB1-"
      },
      "source": [
        "!gzip -d cc.en.300.vec.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIQAQzmhQB_K",
        "outputId": "825fb592-2484-4c51-eede-bb6ac28ada44"
      },
      "source": [
        "path_to_fasttext_file = './cc.en.300.vec'\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_fasttext_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - 6 Vectorizer parameters"
      ],
      "metadata": {
        "id": "Fi0C6PwnoQdO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FeYQiSWQCG9"
      },
      "source": [
        "from tensorflow import string as tf_string\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "embedding_dim = 300 # Dimension of embedded representation \n",
        "vocab_size = 30000 # Number of unique tokens in vocabulary\n",
        "sequence_length = 30 # Output dimension after vectorizing\n",
        "\n",
        "vect_layer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
        "vect_layer.adapt(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAN_NtlRQIL7"
      },
      "source": [
        "voc = vect_layer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PneEQsZQIXa",
        "outputId": "703b4adf-a367-41c9-a6bd-e24713f982a3"
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 25375 words (4625 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INpD6UAIqsM6"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=69, stratify=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Experiment"
      ],
      "metadata": {
        "id": "GL9UpTRwmXi6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WLCss1YgMud",
        "outputId": "4a2079cd-9ae1-459e-c8a0-ffecf62c5c83"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = LSTM(64, activation='relu', return_sequences=True)(emb)\n",
        "x = GRU(64, activation='relu', return_sequences=False)(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 30)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 30, 300)           9000600   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 30, 64)            93440     \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                24960     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,125,273\n",
            "Trainable params: 124,673\n",
            "Non-trainable params: 9,000,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zipdZAYzga40",
        "outputId": "b0888bee-de62-4e07-86b9-6d83e612bccf"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 5\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 9s 156ms/step - loss: 0.6900 - accuracy: 0.5272 - val_loss: 0.6883 - val_accuracy: 0.5425\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 3s 126ms/step - loss: 0.6797 - accuracy: 0.5713 - val_loss: 0.6479 - val_accuracy: 0.6500\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 3s 123ms/step - loss: 0.6161 - accuracy: 0.6932 - val_loss: 0.5572 - val_accuracy: 0.7320\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 3s 127ms/step - loss: 0.5397 - accuracy: 0.7424 - val_loss: 0.5113 - val_accuracy: 0.7665\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 3s 127ms/step - loss: 0.5049 - accuracy: 0.7582 - val_loss: 0.5031 - val_accuracy: 0.7715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu_xBomGoFw1",
        "outputId": "0de7c696-cd68-4553-d92e-7fe43f31233b"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 14ms/step - loss: 0.5171 - accuracy: 0.7456\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5170741081237793, 0.7455999851226807]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qGlwoqyhRK2",
        "outputId": "f59b19b5-c485-4574-b5b7-de7c1215db68"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 74.56% \n",
            "f1-score is 0.7228154281978644% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.83      0.76      5000\n",
            "           1       0.79      0.66      0.72      5000\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.75      0.75      0.74     10000\n",
            "weighted avg       0.75      0.75      0.74     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Experiment"
      ],
      "metadata": {
        "id": "89cjMusTmbNi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf3b927-372b-4324-f4e4-728ee9731e39",
        "id": "JQ0JuAvumbNj"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(emb)\n",
        "x = Bidirectional(GRU(64, activation='relu', return_sequences=False))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 30)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 30, 300)           9000600   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 30, 128)          186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,272,345\n",
            "Trainable params: 271,745\n",
            "Non-trainable params: 9,000,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38443ca5-193e-43f3-89f2-aaf73ab0c8f1",
        "id": "wPg0mgGdmbNk"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 3\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "141/141 [==============================] - 43s 275ms/step - loss: 0.6104 - accuracy: 0.6612 - val_loss: 0.5251 - val_accuracy: 0.7565\n",
            "Epoch 2/3\n",
            "141/141 [==============================] - 32s 226ms/step - loss: 0.5128 - accuracy: 0.7553 - val_loss: 0.5055 - val_accuracy: 0.7695\n",
            "Epoch 3/3\n",
            "141/141 [==============================] - 31s 223ms/step - loss: 0.4794 - accuracy: 0.7755 - val_loss: 0.4958 - val_accuracy: 0.7795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17808c16-7757-469b-8ab0-3dfab5fff1c0",
        "id": "kuhn82C9mbNm"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 20ms/step - loss: 0.5012 - accuracy: 0.7639\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5012386441230774, 0.7638999819755554]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3d3e60-9612-4b1f-d74f-3cac3c627649",
        "id": "d_qER6TymbNn"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 76.39% \n",
            "f1-score is 0.7518133081046987% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.81      0.77      5000\n",
            "           1       0.79      0.72      0.75      5000\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.77      0.76      0.76     10000\n",
            "weighted avg       0.77      0.76      0.76     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Experiment"
      ],
      "metadata": {
        "id": "1AklKKvOmbtL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daafa233-8f08-416d-91f9-660a7ccb755c",
        "id": "Dxs0HzpombtN"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = LSTM(64, activation='relu', return_sequences=True)(emb)\n",
        "x = GRU(64, activation='relu', return_sequences=False)(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 30)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 30, 300)           9000600   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 30, 64)            93440     \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,125,273\n",
            "Trainable params: 124,673\n",
            "Non-trainable params: 9,000,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a5bb83-708d-4f99-846d-7dd244782ecd",
        "id": "DFw91FDNmbtO"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 5\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "586/586 [==============================] - 78s 129ms/step - loss: 0.5007 - accuracy: 0.7526 - val_loss: 0.4482 - val_accuracy: 0.7912\n",
            "Epoch 2/5\n",
            "586/586 [==============================] - 75s 128ms/step - loss: 0.4388 - accuracy: 0.7965 - val_loss: 0.4335 - val_accuracy: 0.7967\n",
            "Epoch 3/5\n",
            "586/586 [==============================] - 75s 129ms/step - loss: 0.4208 - accuracy: 0.8072 - val_loss: 0.4198 - val_accuracy: 0.8077\n",
            "Epoch 4/5\n",
            "586/586 [==============================] - 75s 127ms/step - loss: 0.4102 - accuracy: 0.8132 - val_loss: 0.4098 - val_accuracy: 0.8114\n",
            "Epoch 5/5\n",
            "586/586 [==============================] - 78s 133ms/step - loss: 0.4028 - accuracy: 0.8171 - val_loss: 0.4088 - val_accuracy: 0.8131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af5423e-7735-4567-f01a-6a4612dd1adc",
        "id": "1mLeBkdmmbtP"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 0.4103 - accuracy: 0.8117\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4102845788002014, 0.8116999864578247]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef01ba58-13f2-4aaf-847c-4ff12cba1478",
        "id": "ERKxiVodmbtQ"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 81.17% \n",
            "f1-score is 0.8156632403328439% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.79      0.81      5000\n",
            "           1       0.80      0.83      0.82      5000\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.81      0.81      0.81     10000\n",
            "weighted avg       0.81      0.81      0.81     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Experiment"
      ],
      "metadata": {
        "id": "LjjPcH0QmcDV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0c5511-a5c3-48c5-f3dd-a8c76a86b669",
        "id": "LiZbccmLmcDW"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(emb)\n",
        "x = Bidirectional(GRU(64, activation='relu', return_sequences=False))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 30)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 30, 300)           9000600   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 30, 128)          186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,272,345\n",
            "Trainable params: 271,745\n",
            "Non-trainable params: 9,000,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYC9v1NjmcDX"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 4 \n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07970c2e-a924-470e-cc6f-03e375769983",
        "id": "AeyIzCEkmcDX"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 12s 39ms/step - loss: 0.4055 - accuracy: 0.8127\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4054867923259735, 0.8126999735832214]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30cdd064-26d2-4dd4-8d53-55eeb6d9d6f4",
        "id": "-c5kcLwSmcDY"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 81.27% \n",
            "f1-score is 0.8181023599106536% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.78      0.81      5000\n",
            "           1       0.80      0.84      0.82      5000\n",
            "\n",
            "    accuracy                           0.81     10000\n",
            "   macro avg       0.81      0.81      0.81     10000\n",
            "weighted avg       0.81      0.81      0.81     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Experiment"
      ],
      "metadata": {
        "id": "DNNFkgAqnRc4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75101a5-ba31-4437-da6b-250ddcb8f222",
        "id": "s3GzW_xBnNtg"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = LSTM(64, activation='relu', return_sequences=True)(emb)\n",
        "x = GRU(64, activation='relu', return_sequences=False)(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (TextV  (None, 30)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 30, 300)           9000600   \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 30, 64)            93440     \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,125,273\n",
            "Trainable params: 124,673\n",
            "Non-trainable params: 9,000,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0231619c-ca09-46d3-9050-1939d2ffa1dc",
        "id": "Evo6BgE7nNt8"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 5\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1055/1055 [==============================] - 146s 135ms/step - loss: 0.4725 - accuracy: 0.7740 - val_loss: 0.4279 - val_accuracy: 0.8028\n",
            "Epoch 2/5\n",
            "1055/1055 [==============================] - 141s 134ms/step - loss: 0.4218 - accuracy: 0.8068 - val_loss: 0.4111 - val_accuracy: 0.8117\n",
            "Epoch 3/5\n",
            "1055/1055 [==============================] - 142s 134ms/step - loss: 0.4080 - accuracy: 0.8148 - val_loss: 0.3988 - val_accuracy: 0.8186\n",
            "Epoch 4/5\n",
            "1055/1055 [==============================] - 140s 133ms/step - loss: 0.3988 - accuracy: 0.8196 - val_loss: 0.3934 - val_accuracy: 0.8219\n",
            "Epoch 5/5\n",
            "1055/1055 [==============================] - 145s 138ms/step - loss: 0.3927 - accuracy: 0.8231 - val_loss: 0.3952 - val_accuracy: 0.8191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50318b7-efd4-4f4e-8761-949322f689bb",
        "id": "ncZP_yNgnNt8"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3990 - accuracy: 0.8177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.399008184671402, 0.8177000284194946]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87a3bd6-8b30-4a1f-82a4-d9932e47f52a",
        "id": "wKt55Ur2nNt9"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 81.77% \n",
            "f1-score is 0.824829441721918% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.81      5000\n",
            "           1       0.79      0.86      0.82      5000\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Experiment"
      ],
      "metadata": {
        "id": "lmslxtTInPi5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea7b0e4-441c-408d-e296-a2b08734d81e",
        "id": "wFM3J0NknOLa"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)(x_v)\n",
        "x = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(emb)\n",
        "x = Bidirectional(GRU(64, activation='relu', return_sequences=False))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (TextV  (None, 30)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, 30, 300)           9000600   \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 30, 128)          186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,272,345\n",
            "Trainable params: 271,745\n",
            "Non-trainable params: 9,000,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbb0b70-3289-45b5-9d78-aca59bc3440e",
        "id": "cVGCpYlunOLb"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 3\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1055/1055 [==============================] - 266s 248ms/step - loss: 0.4665 - accuracy: 0.7774 - val_loss: 0.4219 - val_accuracy: 0.8042\n",
            "Epoch 2/3\n",
            "1055/1055 [==============================] - 259s 246ms/step - loss: 0.4151 - accuracy: 0.8105 - val_loss: 0.4088 - val_accuracy: 0.8113\n",
            "Epoch 3/3\n",
            "1055/1055 [==============================] - 258s 244ms/step - loss: 0.4002 - accuracy: 0.8190 - val_loss: 0.3956 - val_accuracy: 0.8191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143e3c7c-d1dd-43ac-8c05-6137fc327139",
        "id": "tJXYH9AynOLc"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3968 - accuracy: 0.8198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3967535197734833, 0.8198000192642212]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3371b7ab-3309-453d-84ef-d9a2e3d120de",
        "id": "bSaDU6AxnOLd"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 81.98% \n",
            "f1-score is 0.8247763516141579% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.79      0.81      5000\n",
            "           1       0.80      0.85      0.82      5000\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 - 8 Vectorizer parameters"
      ],
      "metadata": {
        "id": "o9FhVC8Cp0xp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE7kFdFPp0yF"
      },
      "source": [
        "embedding_dim = 300 # Dimension of embedded representation \n",
        "vocab_size = 100000 # Number of unique tokens in vocabulary\n",
        "sequence_length = 30 # Output dimension after vectorizing\n",
        "\n",
        "vect_layer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
        "vect_layer.adapt(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3jm2ZcDJwxl"
      },
      "source": [
        "voc = vect_layer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516bbafa-d63b-4505-97bb-dd992d042ffb",
        "id": "9ixMPOH8Jwxm"
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 54599 words (45401 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUmgDZNUp0yG"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=69, stratify = y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.Experiment"
      ],
      "metadata": {
        "id": "prOiXlFfyvd-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de35c591-1fd3-4e27-ae67-2638f537a6d0",
        "id": "eiGxBTgHyHQY"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(vocab_size, embedding_dim)(x_v)\n",
        "x = LSTM(64, activation='relu', return_sequences=True)(emb)\n",
        "x = LSTM(64, activation='relu', return_sequences=True)(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_6 (TextV  (None, 30)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_8 (Embedding)     (None, 30, 300)           30000000  \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 30, 64)            93440     \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 30, 64)            33024     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 1920)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 64)                122944    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,251,521\n",
            "Trainable params: 30,251,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe9104e-9989-48d9-d03c-754242f2c0c9",
        "id": "qLT2iddvyHQZ"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 2\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1055/1055 [==============================] - 150s 140ms/step - loss: 0.4295 - accuracy: 0.8005 - val_loss: 0.3915 - val_accuracy: 0.8229\n",
            "Epoch 2/2\n",
            "1055/1055 [==============================] - 145s 138ms/step - loss: 0.3509 - accuracy: 0.8451 - val_loss: 0.4013 - val_accuracy: 0.8202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fe3f13-34c9-40e1-cd21-27b60389857a",
        "id": "7CmjfRsmyHQa"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step - loss: 0.4006 - accuracy: 0.8198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40057894587516785, 0.8198000192642212]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e37d87-5d21-42b2-ab24-3ad503910fe8",
        "id": "NphrSQMpyHQb"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 81.98% \n",
            "f1-score is 0.8121742755889098% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.86      0.83      5000\n",
            "           1       0.85      0.78      0.81      5000\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.Experiment"
      ],
      "metadata": {
        "id": "Os7OG-a_zcpc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03cc266c-b762-4d32-e540-9b16c1a04170",
        "id": "cy3-xcEPze4Y"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(1,), dtype=tf_string)\n",
        "x_v = vect_layer(input_layer)\n",
        "emb = keras.layers.Embedding(vocab_size, embedding_dim)(x_v)\n",
        "x = Bidirectional(LSTM(128, activation='relu', return_sequences=True))(emb)\n",
        "x = Bidirectional(LSTM(64, activation='relu', return_sequences=True))(x)\n",
        "x = Bidirectional(GRU(64, activation='relu', return_sequences=True))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(64, 'relu')(x)\n",
        "x = keras.layers.Dense(32, 'relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "output_layer = keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_6 (TextV  (None, 30)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_9 (Embedding)     (None, 30, 300)           30000000  \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirectio  (None, 30, 256)          439296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (None, 30, 128)          164352    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirecti  (None, 30, 128)          74496     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 3840)              0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 64)                245824    \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,926,081\n",
            "Trainable params: 30,926,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fbbec61-e2d5-40ec-bac7-4554f1da6ee9",
        "id": "mYux1GZCze4Z"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=70, restore_best_weights=True)\n",
        "\n",
        "batch_size = 768\n",
        "epochs = 2\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), callbacks=[es], epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1055/1055 [==============================] - 394s 365ms/step - loss: 0.4279 - accuracy: 0.8007 - val_loss: 0.3912 - val_accuracy: 0.8231\n",
            "Epoch 2/2\n",
            "1055/1055 [==============================] - 385s 365ms/step - loss: 0.3473 - accuracy: 0.8473 - val_loss: 0.3877 - val_accuracy: 0.8252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6e9ebd-a184-462a-cd2d-c4763ca89a38",
        "id": "c0_cwCeDze4Z"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 9s 29ms/step - loss: 0.3860 - accuracy: 0.8236\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3860154151916504, 0.8235999941825867]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42851d7-8c9c-4c9f-b938-48a9d9210576",
        "id": "TFTkzm_bze4Z"
      },
      "source": [
        "y_pred=model.predict(x_test)\n",
        "\n",
        "accuracy_sc = accuracy_score(y_pred=y_pred.round(),y_true=y_test)*100\n",
        "f1_sc = f1_score(y_pred=y_pred.round(),y_true=y_test)\n",
        "\n",
        "print(\"Accuracy score is {}% \".format(accuracy_sc))\n",
        "print(\"f1-score is {}% \".format(f1_sc))\n",
        "print(classification_report(y_pred=y_pred.round(),y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 82.36% \n",
            "f1-score is 0.8238466147393648% \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82      5000\n",
            "           1       0.82      0.82      0.82      5000\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model"
      ],
      "metadata": {
        "id": "yTV3ooWrJfIw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGjlL5KbHw4s",
        "outputId": "bef70e7c-13b7-4607-954e-6589facc5625"
      },
      "source": [
        "model.save('FT_forth_done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: lstm_forth_done/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: lstm_forth_done/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fe1149d9b90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7fe116511c10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBk_bNb9MrDZ",
        "outputId": "e358c89b-4676-4daa-86ea-d95f30b69ff0"
      },
      "source": [
        "!zip -r /content/FTforthD.zip /content/FT_forth_done/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/lstm_forth_done/ (stored 0%)\n",
            "  adding: content/lstm_forth_done/saved_model.pb (deflated 78%)\n",
            "  adding: content/lstm_forth_done/assets/ (stored 0%)\n",
            "  adding: content/lstm_forth_done/variables/ (stored 0%)\n",
            "  adding: content/lstm_forth_done/variables/variables.index (deflated 66%)\n",
            "  adding: content/lstm_forth_done/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/lstm_forth_done/keras_metadata.pb (deflated 90%)\n"
          ]
        }
      ]
    }
  ]
}